[
  {
    "path": "models/2023-11-28-advanced-ml-rnn/",
    "title": "Lesson 5: Advanced Machine Learning (Ⅳ)",
    "description": "RNN stands for \"recurrent neural network\". In an RNN, prediction depends not only on the features of the current time point, but also the time points that came before the current time point. As a result, RNN's are most useful for modelling patterns in timeseries data. In this section, we're introducing how to implement an RNN model for predicting the next item.",
    "author": [],
    "date": "2023-12-04",
    "categories": [],
    "contents": "\n\nContents\n1. Ecological time-series (question)\n2. Recurrent neural networks\n2.1 Forward NN and RNN\n2.2 The feedback loop\n2.3 Setting R for RNN\n\n3. Classification with RNN\n3.1 Set model parameters\n3.2 Pre-processing data\n3.3 Building and training RNN\n3.3.3 Evaluate RNN model\n\n4. Regression with RNN\n4.1 Load the libraries & the dataset\n4.2 Data preparison\n\n4.3 Building lstm RNN\n\n1. Ecological time-series (question)\nMost phenomena in ecology are assessed with repeated measurements of environmental variables. The time-series analysis is to describe and quantify the dynamic behavior underlying these observations, to link different observations and give hints towards the origin of observed phenomena. Although the dynamics of the time series are investigated with a variety of statistical techniques and nonlinear methods, which allow the separation of short- and long-term components, the crucial question is how to find the optimal temporal resolution (Lange, H. ENCYCLOPEDIA OF LIFE SCIENCES, 2005). This is a big question of time-series analysis in ecology.\nThe optimal temporal resolution for observing an ecological phenomena is very important. An important aspect of a time series is whether the measurements are taken in an equidistant manner or not. In particular, a decision has to be made if unequal measure intervals are regarded as imprecise, or count as gap or missing values. In addition, there is no fully satisfying procedure to fill these gaps with artificial values, including interpolation. Also, the gaps is linked to the significance of (auto-)correlations for the series.\nTo solve optimal temporal resolution, there have two types of analysis methods: methods for analysis of temporal structures and methods for modelling them. Analysis methods aim to fully understand the dynamics and points to plausible explanations. But models seek to reconstruct observed and predict future behavior, without understanding it. Here the approach worth mention is RNN, a flexible technique to detect and describe almost any structure in multivariate data sets. it is capable of providing empirical on-line n-step-ahead prediction by adjustment of weights of connections, and therefor can be used to detect optimal temporal resolution based on the model performance. We use different length of time series to predict a given day, and compare their model accuracy. The higher the model accuracy, the more likely the length approximates to the optimal temporal resolution.\n2. Recurrent neural networks\n2.1 Forward NN and RNN\nRNN works on the principle of saving the output of a hidden layer and feeding this back to the input for predicting its output. Below is how to convert a Feed-Forward Neural Network into a RNN. Compared with the feed-forward neural network, RNN has additional loop from a neuron to itself and information transformation from the first neuron to second, third, …, in the hidden layer.\n\nRNN is designed to process sequences of data, and works well for jobs requiring sequences, such as time series data.\n2.2 The feedback loop\nRNN achieves a memory through a feedback loop in the cell. It is the main difference between a RNN and a traditional NN. The feedback loop allows information to be passed in a layer in contrast to feedforward NN in which information is only passed between layers.\nRNNs must define what information is relevant enough to be kept in the memory. For this, different types of RNN evolved: 1) Traditional RNN, 2) Long-Short-term-Memory RNA (LSTM), and 3) Gated Recurrent Unit RNA.\n2.2.1 Recurrent neural network\nFor RNN, through the feedback loop the output of one RNN cell is used as an input by the same cell. Then each cell has two inputs: the past and the present. Using information of the past results in a short term memory. We unfold the feedback loop of an RNN cell (see the following figure). The length of the unfolded cell is equal to the number of the time steps of the input sequence.\n\nIn each cell the input of the current time step x (present value), the hidden state h of the previous time step (past value) and a bias are combined and then limited by an activation function to determine the hidden state of the current time step. The weights W of the RNN are updated through a backpropagation in time (BPTT) algorithm.\n2.2.2 Long-Short-Term-Memory (LSTM)\nLSTMs are a special type of RNNs which tackle the vanishing/exploding problems of a simple RNN. Saying, we have a sequence of 4 time points and using them to predict next time. The flow chart of a LSTM can be designed as follows.\n\nThe key to LSTMs is the cell state. The cell state has 3 gates, forget gate, input gate, and ouput gate. They filter and control the flow of information and determine which information is kept or disregarded (see the following figure).\n\n2.2.3 Gated Recurrent Unit (GRU)\nSimilar to LSTMs, GRU solves the vanishing gradient problem of simple RNNs. The difference to LSTMs is that GRUs use fewer gates, which do not have a separate internal memory, i.e., cell state, but relies on the hidden state as a memory, leading to a simpler architecture.\n2.3 Setting R for RNN\nFirst, we need to make sure that R environment is set up. We are going to load in a couple of utility packages.\n\n\n# rm(list = ls())\n# library(keras) # for deep learning\n# library(tidyverse) # general utility functions\n# library(caret) # machine learning utility functions\n\n\nNext, we need to read data, and look at the first couple of rows of a dataframe to make sure the data looks reasonable.\n\n\n# weather_data <- read_csv(\"seattleWeather_1948-2017.csv\") # read in our data\n# nrow(weather_data)\n# head(weather_data) # check out the first few rows\n\n\n3. Classification with RNN\n3.1 Set model parameters\nWe have the dataset of seattle weather. It can be downloaded from the website. It contains information on the weather in Seattle for every single day between Jan 1, 1948 and Dec 12, 2017. We want to predict whether it is rain or not of a given day based on the weather observation of the previous six day For more details, see the website.\nWe set 3 parameters for model: 1) The maximum length of the sequence that we’re going to look at to try and predict the next item; 2) The batch size, which is the number of distinct sequences to look at at one time during training; 3) The total number of epochs to train for.\n\n\n# max_len <- 6 # based on the six days for predicting next day\n# batch_size <- 32 # number of sequences to look at at one time during training\n# total_epochs <- 15 # how many times we'll look @ the whole dataset\n# set.seed(123) # set a random seed for reproducability\n\n\n3.2 Pre-processing data\n3.2.1 Generating samples\nWe need to do some pre-processing to get our data ready to feed into our model. First, we select the column we’re interested in predicting and summarize it for checking whether the dataset is balanced and has missing values.\n\n\n# rain <- weather_data$RAIN # select the colum with info on how often it rained\n# nrow(weather_data)\n# table(rain) # summery\n\n\nNext task is to chop this timeseries into samples of our max_length + 1. We can start at the beginning of the vector, and chop it into the non-overlapping chunks of max_length + 1. It will only give us around 3600 (nrow(weather_data)/7) examples (it isn’t enough to train a deep learning model). We can stretch out our data by using a moving-block sub-sampling to cut up our vector into overlapping chunks. That is, we move a block of max_length + 1 long and overlap 3 units for getting blocks like this.\n\n\n\nFor cutting the text in overlapping sample sequences of max_len characters, we perform the following code.\n\n\n# # get a list of start indexes for our (overlapping) chunks\n# start_indexes <- seq(1, length(rain) - (max_len + 1), by = 3)\n# # create an empty matrix to store our data in\n# weather_matrix <- matrix(nrow = length(start_indexes), ncol = max_len + 1)\n# # fill our matrix with the overlapping slices of our dataset\n# for (i in 1:length(start_indexes)){\n#   weather_matrix[i,] <- rain[start_indexes[i]:(start_indexes[i] + max_len)]\n# }\n\n\n3.2.2 Correcting the data\nNow that we have our sample data in a tidy matrix, we just need to do a couple of housekeeping things to make sure everything is good to go.\nMake sure your matrix is numeric. Since Keras expects a numeric matrix, we’re going to convert our data from boolean to numeric by multiplying everything by one.\nRemove any NaN. If ending up with na in data, the model will compile and train just fine. But the model will prediction all be NaN. In this case we do need to do it, as is shown in the diagram above, our data slicing approach ended up adding na’s to the dataset.\n\n\n# # make sure it's numeric\n# weather_matrix <- weather_matrix * 1\n# # remove na's if you have them\n# if(anyNA(weather_matrix)){\n#     weather_matrix <- na.omit(weather_matrix)\n# }\n\n\n3.2.3 Training and test sets\nNow, we can get down to preparing it to be fed into our model. First, we need to split our dataset into the input (the 6 previous days) and the output (the single day we’re interested in predicting). Following convention, we call our inputs X and output y.\n\n\n# X <- weather_matrix[,-ncol(weather_matrix)]\n# y <- weather_matrix[,ncol(weather_matrix)]\n\n\nNow we need to split our data in to the test and training sets using the createDataPartition() function from the caret package.\n\n\n# training_index <- createDataPartition(y, p = .9, list = FALSE, times = 1)\n# # training data\n# X_train <- array(X[training_index,], dim = c(length(training_index), max_len, 1))\n# y_train <- y[training_index]\n# \n# # test data\n# X_test <- array(X[-training_index,], dim = c(length(y) - length(training_index), max_len, 1))\n# y_test <- y[-training_index]\n\n\n3.3 Building and training RNN\n3.3.1 Specifying a RNN model\nFirst, we tell Keras what type of model we want to build & initialize, Here we specify a sequential model (another option is to utilize the functional API). Let’s stick with the sequential model with an input layer, a hidden layer and an output layer.\n\n\n# model <- keras_model_sequential() # initialize our model\n\n\nInput layer\nBecause model takes raw data as input, we specify what the dimensions of our data is. Let’s look at the dimensions of the matrix that we’ll be passing into our model to figure out what our input_shape should be.\n\n\n# dim(X_train)\n\n\nIn this case, the 1st dimension is the number of our training samples, the 2nd is the length of input sequence (max_len), and the 3rd refers to the number of features (only one: whether it rained or not). We get the dimensions of the input array using the dim() function and pass those in as the input_shape.\nThe “units” argument tells us how many neurons in the input layer. For a sequence modelling, it makes sense to have the same number of units as the items in our input sequence, which we decided with the max_len parameter, so we are going to pass that to our model directly here.\n\n\n# # our input layer\n# model %>%\n#     layer_dense(input_shape = dim(X_train)[2:3], units = max_len)\n\n\nHidden layer\nNow let’s tell Keras about our hidden layer. In this model, we use a single hidden layer. Inside it, each neuron is a model of our input sequence, where the 2nd item depends on the 1st item, the 3rd item on the 1st and 2nd items, the 4th item on the 1st, 2nd and 3th items, and so on. Since this is a recurrent network layer, there will be six different little models of our six-item input sequences.\n\n\n# model %>% \n#     layer_simple_rnn(units = 6)\n\n\nOutput layer\nAt this point, our model has 6 different outputs, one for each of the neurons in the hidden layer. But we want to predict only one output: whether it will rain the next day. So, we need to add an output layer that will take all information and squash it down to a single value. We specify this with the “units” argument. Here the units will be 1.\nWe use a sigmoid activation function to take all inputs into a cell and transforms them into a number between zero and one, which is the probability that it will rain on the next day.\n\n\n# model %>%\n#     layer_dense(units = 1, activation = 'sigmoid') # output\n\n\nNow let’s take a look at our architecture. We can do this by using summary() to look at our model.\n\n\n# # look at our model architecture\n# summary(model)\n\n\n3.3.2 Compiling and training\nWe need to compile it and specify what the loss and optimizer, as well as what metric to track (if any).\n\n\n# model %>% compile(loss = 'binary_crossentropy', \n#                   optimizer = 'RMSprop', \n#                   metrics = c('accuracy'))\n\n\nWe should have the validation split for evaluation, and need to pick our batch size and epochs for training.\nEpochs and batch size\nThe number of epochs is the number of times our model see our training dataset during training. Batch size denots how many samples that are fed into our model at a time. Our batch size is less than the total number of training samples, thus technically “mini batches”.\nValidation split\nFor validing our model we’re setting a validation set to 0.1. This set is different from the test data at the beginning, which will be used to evaluate the final model once we’re done training it.\nTraining the model\nNow that we’ve got everything set up, it’s time to train our model!\n\n\n# trained_model <- model %>% fit(\n#     x = X_train, # sequence we're using for prediction \n#     y = y_train, # sequence we're predicting\n#     batch_size = batch_size, \n#     epochs = total_epochs, \n#     validation_split = 0.1) \n\n\n3.3.3 Evaluate RNN model\nIn this case, we wanted to predict whether it would rain tomorrow or not next day, so we’re probably going to be interested in looking at how accurate our predictions are.\nFirst, we can look at how well our model did on our validation data during training after training. This tells us the accuracy and loss on both our training data (first two rows) and validation data (second two rows) after the last epoch of training. We can see that, for our validation data, our model had 74% accuracy in predicting weather it would rain the next day or not based on the previous six days.\n\n\n# trained_model\n# plot(trained_model)\n\n\nThis looks pretty good! We can probably have stopped training a couple of epoch earlier, since both accuracy and loss flattened out around 5 epochs.\nNow’s the time when we dig it back up and use the test data to check our how good our model is at predicting the weather. For a little more nuanced look into our model results, we’re going to use a confusion matrix.\n\n\n# # Predict the classes for the test data\n# classes <- model %>% predict(X_test, batch_size = batch_size) %>%\n#   `>`(0.5) %>% k_cast(\"int32\")\n# \n# # Confusion matrix\n# table(y_test, as.vector(classes))\n\n\nWe can also find out what our model’s loss and accuracy on our training data.\n\n\n# model %>% evaluate(X_test, y_test, batch_size = batch_size)\n\n\n4. Regression with RNN\nWe use the U.S. long-term interest rates data to illustrate the regression with RNN. The data are available here. This is a monthly data from Jan 2007 to March 2018. For the full code, see the website\n4.1 Load the libraries & the dataset\n\n\n# rm(list = ls())\n# \n# # loading and checking data\n# us_data <- read.csv(\"us_data.csv\", stringsAsFactors = FALSE)\n# class(us_data)\n# str(us_data)\n# head(us_data)\n# \n# # converting TIME to date\n# library(\"anytime\") \n# us_data$Time <- anydate(us_data$TIME)\n# class(us_data$Time) # view R class of data\n# head(us_data$Time)\n# us_data\n# \n# # quickly ploting data\n# ggplot(us_data, aes(x=Time, y=Value)) + \n#   geom_line(color = \"blue\") +\n#   theme_classic() + \n#   ggtitle(\"U.S. long-term interest rates\") + xlab(\"Time\") + ylab(\"Value\")\n\n\n4.2 Data preparison\nstationary\nThis is done by getting the difference between two consecutive values in the timeseries. This transformation, commonly known as differencing, removes components in the data that are time dependent. Furthermore, it is easier to model using the difference, rather than the raw values, and the resulting model has a higher predictive power.\n\n\n# # transform data to stationarity\n# diffed = diff(us_data$Value, differences = 1)\n# head(diffed)\n\n\nLagged dataset\nLSTM expects the data to be in a supervised learning mode. That is, having a target variable Y and predictor X. To achieve this, we transform the series by lagging the series and have the value at time (t−k) as the input and value at time t as the ouput, for a k-step lagged dataset.\n\n\n# lag_transform <- function(x, k= 1){\n#     \n#       lagged =  c(rep(NA, k), x[1:(length(x)-k)])\n#       DF = as.data.frame(cbind(lagged, x))\n#       colnames(DF) <- c(paste0('x-', k), 'x')\n#       DF[is.na(DF)] <- 0\n#       return(DF)\n# }\n# supervised = lag_transform(diffed, 1)\n# head(supervised)\n\n\ntraining and testing\nUnlike in analysis where training and test data sets are randomly sampled, with time series data the order of the observations does matter. The following code split the first 70% of the series as training set and the remaining 30% as test set.\n\n\n# ## split into train and test sets\n# N = nrow(supervised)\n# n = round(N *0.7, digits = 0)\n# train = supervised[1:n, ]\n# test  = supervised[(n+1):N,  ]\n\n\nNormalize the data\nJust like in any other neural network model, we rescale the input data X to the range of the activation function. As shown earlier, the default activation function for LSTM is sigmoid function whose range is [-1, 1]. The code below will help in the transformation. Note that the min and max values of the training data set are the scaling coefficients used to scale both the training and test data sets as well as the predicted values. This ensures that the min and max values of the test data do not influence the model.\n\n\n# scale_data = function(train, test, feature_range = c(0, 1)) {\n#   x = train\n#   fr_min = feature_range[1]\n#   fr_max = feature_range[2]\n#   std_train = ((x - min(x) ) / (max(x) - min(x)  ))\n#   std_test  = ((test - min(x) ) / (max(x) - min(x)  ))\n#   \n#   scaled_train = std_train *(fr_max -fr_min) + fr_min\n#   scaled_test = std_test *(fr_max -fr_min) + fr_min\n#   \n#   return( list(scaled_train = as.vector(scaled_train), scaled_test = as.vector(scaled_test) ,scaler= c(min =min(x), max = max(x))) )\n#   \n# }\n# \n# \n# Scaled = scale_data(train, test, c(-1, 1))\n# \n# y_train = Scaled$scaled_train$x\n# x_train = Scaled$scaled_train$`x-1`\n# \n# y_test = Scaled$scaled_test$x\n# x_test = Scaled$scaled_test$`x-1`\n# \n# ## inverse-transform\n# invert_scaling = function(scaled, scaler, feature_range = c(0, 1)){\n#   min = scaler[1]\n#   max = scaler[2]\n#   t = length(scaled)\n#   mins = feature_range[1]\n#   maxs = feature_range[2]\n#   inverted_dfs = numeric(t)\n#   \n#   for( i in 1:t){\n#     X = (scaled[i]- mins)/(maxs - mins)\n#     rawValues = X *(max - min) + min\n#     inverted_dfs[i] <- rawValues\n#   }\n#   return(inverted_dfs)\n# }\n\n\n4.3 Building lstm RNN\nDefine the model\nWe set the argument stateful= TRUE so that the internal states obtained after processing a batch of samples are reused as initial states for the samples of the next batch. Since the network is stateful, we provide the input batch in 3-d array [samples, timesteps, features] from the current [samples, features], where:\nSamples: Number of observations in each batch, also known as the batch size.\nTimesteps: Separate time steps for a given observations. Here the timesteps = 1\nFeatures: For a univariate case, the features = 1\nThe batch size must be a common factor of sizes of both the training and test samples. 1 is always a sure bet. A nice explanation of LSTM input can be found here.\n\n\n# # Reshape the input to 3-dim\n# dim(x_train) <- c(length(x_train), 1, 1)\n# \n# # specify required arguments\n# X_shape2 = dim(x_train)[2]\n# X_shape3 = dim(x_train)[3]\n# batch_size = 1 # must be a common factor of both the train and test samples\n# units = 1 # can adjust this, in model tuninig phase\n# \n# model <- keras_model_sequential() \n# model %>%\n#   layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful= TRUE) %>%\n#   layer_dense(units = 1)\n\n\nCompile the model\nHere I have specified the mean_squared_error as the loss function, Adaptive Monument Estimation (ADAM) as the optimization algorithm and learning rate and learning rate decay over each update. Finaly, I have used the accuracy as the metric to assess the model performance.\n\n\n# model %>% compile(\n#   loss = 'mean_squared_error',\n#   optimizer = optimizer_adam(),\n#   metrics = c('accuracy')\n# )\n#\n# summary(model)\n\n\nFit the model\nWe set the argument shuffle = FALSE to avoid shuffling the training set and maintain the dependencies between xi and xi+t. LSTM also requires resetting of the network state after each epoch. To achieve this we run a loop over epochs where within each epoch we fit the model and reset the states via the argument reset_states().\n\n\n# Epochs = 50   \n# for(i in 1:Epochs ){\n#   model %>% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)\n#   model %>% reset_states()\n# }\n\n\nModel evaluation\n\n\n# L = length(x_test)\n# scaler = Scaled$scaler\n# predictions = numeric(L)\n# \n# for(i in 1:L){\n#      X = x_test[i]\n#      dim(X) = c(1,1,1)\n#      yhat = model %>% predict(X, batch_size=batch_size)\n#      # invert scaling\n#      yhat = invert_scaling(yhat, scaler,  c(-1, 1))\n#      # invert differencing\n#      yhat  = yhat + Series[(n+i)]\n#      # store\n#      predictions[i] <- yhat\n# }\n\n\n\n\n\n",
    "preview": "models/2023-11-28-advanced-ml-rnn/rnn.png",
    "last_modified": "2023-12-04T14:51:55+08:00",
    "input_file": "advanced-ml-rnn.knit.md"
  },
  {
    "path": "models/2023-10-17-one-shot-learning-with-r/",
    "title": "Lesson 3: One Shot Learning with R",
    "description": "One-shot learning is a machine learning algorithm using a limited amount of training set data to compare the similarities and differences between two images. This section will introduce you to build one-shot learning model with R keras.",
    "author": [],
    "date": "2023-11-13",
    "categories": [],
    "contents": "\n\nContents\n1. Learning algorithm with limited data\n1.1 Zero-Shot Learning\n1.2 One-Shot Learning\n1.3 Few-Shot Learning\n\n2. Building a one-shot learning model\n2.1 Loading and spliting data\n2.2 Building a self define generator\n2.3 Building and training a model\n2.4 Verifing with test data\n\n3. Import things of deep learning\n3.1 Difference between ANN and CNN\n3.2 keras generators, Callback and Tensorboard\n\n\n1. Learning algorithm with limited data\nTraditional machine learning algorithms, including classic and advanced, require large amounts of labelled data for training. However, in real world, obtaining such data can be expensive, time-consuming, or even impossible. Zero-, one- and few-shot learning algorithms are designed to address the challenge of learning from limited labelled data. Each approach refers to the number of examples available for training and the level of generalization required.\n1.1 Zero-Shot Learning\nThe model is designed to train with no examples for certain classes. It has the two following characteristics.\nGeneralization: The goal is to classify instances from classes not seen during training. The model learns to generalize its knowledge to unseen classes.\nCommon Technique: Transfer learning, semantic embeddings, and attribute-based methods are often used in zero-shot learning. These approaches leverage auxiliary information about classes to perform classification.\n1.2 One-Shot Learning\nThe model is designed to train with just one example per class. It has the following charateristics.\nGeneralization: The goal is to learn a representation that can differentiate between classes based on a single example.\nCommon Technique: Siamese, matching, and prototypical networks are often used in one-shot learning. These architectures focus on learning relationships between examples.\n1.3 Few-Shot Learning\nThis is a more general term that encompasses both one-shot learning and scenarios where a small number of examples (more than one) per class are available. It has the following charateristics.\nGeneralization: The goal is to enable the model to classify instances from classes with very few training examples.\nCommon Techniques: These methods include variants of one-shot learning models and meta-learning strategies. These techniques teach the ability to adapt quickly to new tasks or classes.\n2. Building a one-shot learning model\nWe can learn the basics of Keras by walking through a simple example of the MNIST dataset. It consists of 28 x 28 grayscale images of handwritten digits. The dataset includes labels for each image, telling us which digit it is. For machine learning, such as ANN, with the dataset, please visit the site and another one\nHere we build one-shot learning model with a dataset of mnist number. The code modified according to this page.\n2.1 Loading and spliting data\nFirst, we load and split the data into training, validation, and testing sets using the Keras and abind libraries in R. Here’s the code:\n\n\n# # the first three lines should be run for checking the python env\n# # rm(list = ls())\n# # library(reticulate) # loading virtual environment for project\n# # py_config() # By default, the env is ~/.virtualenvs/r-reticulate\n# library(reticulate)\n# library(keras) # loading the package for data and modelling\n# library(abind) # operating multidimensional arrays, which are often expressed any image.\n# # mnist <- dataset_mnist() # load the dataset from the keras package\n# # np <- import(numpy)\n# # mnist <- np$load(\"/home/tank/Desktop/ecodatasci/images/mnist.npz\") # full path\n# mnist <- dataset_mnist(\"/home/tank/Desktop/ecodatasci/images/mnist.npz\") # full path\n\n\nLet’s explore the format of the dataset before training the model.\n\n\n# str(mnist)\n\n\nWe have four arrays: train_images and train_labels, test_images and test_labels. We can separate each array from each other by performing the following code.\n\n\n# train_images1 <- mnist$train$x\n# train_labels1 <- mnist$train$y\n# test_images  <- mnist$test$x \n# test_labels  <- mnist$test$y\n\n\ntrain_images1 contain 60,000 images. Each image shows 28 x 28 pixels, which values ranging between 0 and 255. train_labels1 with 60000 elements are arrays of integers, ranging from 0 to 9.\n\n\n# dim(train_images1)\n# dim(train_labels1)\n# train_labels1[1:20]\n\n\ntest_images contain 10000 images, which is used to evaluate how accurately the network learned. Each image is represented as 28 x 28 pixels.\n\n\n# dim(test_images)\n# dim(test_labels)\n\n\nUsing Keras, we can set aside a portion of the training data for validation. This helps monitor model performance and detect overfitting. At the point, we have 48,000 training. Additional 12,000 data are validation.\n\n\n# set.seed(9478)\n# val_idx      <- sample(1:nrow(train_images1),\n#             size = ceiling(0.2*nrow(train_images1)), # the smallest integer > the value\n#                        replace = F)\n# val_images   <- train_images1[val_idx,,] # the third comma means the channel of accolor image\n# val_labels   <- train_labels1[val_idx]\n# train_images <- train_images1[-val_idx,,]\n# train_labels <- train_labels1[-val_idx]\n\n\nThe pixel values fall in the range of 0 to 255. We scale pixel values to a range of 0 (black) to 1 (white) before feeding to model. You can visualize the mnist’s data as blow. The title is its label and image is its array.\n\n\n# par(mar = c(0,0,4,0)) # seting the bottom, left, top and right margins of a plot region.\n# i <- 1\n# plot(as.raster(train_images[i,,]/255)) # i and two comma denote 3-dimensional array of an image\n# title(train_labels[i])\n\n\n2.2 Building a self define generator\nThis step includes: setting parameters, building self define generator, building self define layer, building self define backend function.\nParameter Setting\nIn any machine learning model, you would typically need to set various parameters for configuring the model.\n\n\n# num_classes  <- 10 # only number : 0,1,2,3,4,5,6,7,8,9 \n# shape_size   <- 28 # mnist shape (28,28)\n# train_batch  <- 20 \n# val_batch    <- 20 \n# test_batch   <- 1\n\n\nWe create train_data_list and val_data_list to hold the training and validation data.The code is a general template for organizing and reshaping data for using Keras. It can be adapted to other datasets with modifications to class labels, images, and dimensions.\n\n\n# train_data_list    <- list() \n# grp_kind     <- sort(unique(train_labels)) # # get unique class labels from data \n#   for( grp_idx in 1:length(grp_kind)) { # iterate over each class, grp_idx = 1,  \n#     label    <- grp_kind[grp_idx]  # get label of the current class  \n#     tmp_images <- train_images[train_labels==label,,] # get images of the current class \n#     tmp_images     <- array(tmp_images, dim = c(dim(tmp_images), 1))  # reshape to 4D (batch_size, height, width, channels) for keras's generator.  \n#     train_data_list[[grp_idx]] <- list( data  = tmp_images, # x                   \n#                                         label = train_labels[train_labels==label])# y\n#   }  \n# \n# val_data_list      <- list() \n# grp_kind     <- sort( unique( val_labels ) )   \n#   for( grp_idx in 1:length(grp_kind) ) { # grp_idx = 1     \n#     label                      <- grp_kind[grp_idx]     \n#     tmp_images                 <- val_images[val_labels==label,,]     \n#     tmp_images                 <- array( tmp_images , dim = c( dim(tmp_images) , 1) )     \n#     val_data_list[[grp_idx]]   <- list( data  = tmp_images ,                                         \n#                                         label = val_labels[val_labels==label]      \n#                                       )   \n#   }\n\n\nTo determine the exact number of samples for each class, you can inspect the length of the list within the train_data_list. That is, using length(train_data_list[[1]]$lebal) gives you the number of samples for the first class. You can repeat this for each class to get the number of samples for each class.\n\n\n# # Initialize a variable to store the sum\n# total_sum <- 0\n# \n# # Use a for loop to sum values from 1 to 10\n# for (i in 1:10) {\n#   counts <- length(train_data_list[[i]]$label)\n#   total_sum <- total_sum + counts\n# }\n# \n# # Print the total sum\n# cat(\"The sum of values from 1 to 10 is:\", total_sum, \"\\n\")\n\n\nSelf a define generator\nData augmentation is a technique to increase the diversity of your training dataset by applying various transformations to images, and improves the model’s generalization and robustness. Here we first build generators with image_data_generator for each mnist’s number to generalize the number, and then collect all numbers’ generators into a list.\n\n\n# train_datagen = image_data_generator( # data argumentation\n#   rescale = 1/255          , # scaling pixel values to the range [0, 1]\n#   rotation_range = 5       , # randomly rotate images by up to 5 degrees\n#   width_shift_range = 0.1  , # shift by up to 10% of the image's width\n#   height_shift_range = 0.05, # shift by up to 5% of the image's height\n#   #shear_range = 0.1,\n#   zoom_range = 0.1         , # randomly zoom in/out by up to 10%\n#   horizontal_flip = FALSE  , # disable horizontal flipping\n#   vertical_flip = FALSE    , # disable vertical flipping\n#   fill_mode = \"constant\"     # fill mode for new pixels (constant value)\n# )\n\n\nWe will train the model to differentiate between digits of different classes. For example, digit 0 needs to be differentiated from the rest of the digits (1 through 9). To carry this out, we will select N random images from class A (for example, for digit 0) and pair them with N random images from another class B (for example, for digit 1). The following code prepares data generators for individual classes, making it easier to handle and process data during training and validation. It is especially useful for one-shot learning tasks.\n\n\n# train_0_generator <- flow_images_from_data( # for 0 number\n#   x = train_data_list[[1]]$data  ,   \n#   y = train_data_list[[1]]$label ,   \n#   train_datagen                  , # data augmentation configuration  \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1  # for one-shot learning, each batch contains one pair of images \n# )\n# \n# train_1_generator <- flow_images_from_data( # for 1 number  \n#   x = train_data_list[[2]]$data  ,   \n#   y = train_data_list[[2]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_2_generator <- flow_images_from_data( # for 2 number  \n#   x = train_data_list[[3]]$data  ,   \n#   y = train_data_list[[3]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_3_generator <- flow_images_from_data( # for 3 number  \n#   x = train_data_list[[4]]$data  ,   \n#   y = train_data_list[[4]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_4_generator <- flow_images_from_data( # for 4 number  \n#   x = train_data_list[[5]]$data  ,   \n#   y = train_data_list[[5]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_5_generator <- flow_images_from_data( # for 5 number  \n#   x = train_data_list[[6]]$data  ,   \n#   y = train_data_list[[6]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_6_generator <- flow_images_from_data( # for 6 number  \n#   x = train_data_list[[7]]$data  ,   \n#   y = train_data_list[[7]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_7_generator <- flow_images_from_data( # for 7 number  \n#   x = train_data_list[[8]]$data  ,   \n#   y = train_data_list[[8]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_8_generator <- flow_images_from_data( # for 8 number   \n#   x = train_data_list[[9]]$data  ,   \n#   y = train_data_list[[9]]$label ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# train_9_generator <- flow_images_from_data( # for 9 number   \n#   x = train_data_list[[10]]$data ,   \n#   y = train_data_list[[10]]$label,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_test_datagen = image_data_generator(\n#   rescale = 1/255\n# )\n# \n# val_0_generator <- flow_images_from_data( # for 0 number  \n#   x = val_data_list[[1]]$data    ,   \n#   y = val_data_list[[1]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_1_generator <- flow_images_from_data( # for 1 number  \n#   x = val_data_list[[2]]$data    ,   \n#   y = val_data_list[[2]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_2_generator <- flow_images_from_data( # for 2 number   \n#   x = val_data_list[[3]]$data    ,   \n#   y = val_data_list[[3]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_3_generator <- flow_images_from_data( # for 3 number   \n#   x = val_data_list[[4]]$data    ,   \n#   y = val_data_list[[4]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_4_generator <- flow_images_from_data( # for 4 number   \n#   x = val_data_list[[5]]$data    ,   \n#   y = val_data_list[[5]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_5_generator <- flow_images_from_data( # for 5 number  \n#   x = val_data_list[[6]]$data    ,   \n#   y = val_data_list[[6]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_6_generator <- flow_images_from_data( # for 6 number  \n#   x = val_data_list[[7]]$data    ,   \n#   y = val_data_list[[7]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_7_generator <- flow_images_from_data( # for 7 number  \n#   x = val_data_list[[8]]$data    ,   \n#   y = val_data_list[[8]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_8_generator <- flow_images_from_data( # for 8 number  \n#   x = val_data_list[[9]]$data    ,   \n#   y = val_data_list[[9]]$label   ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n# \n# val_9_generator <- flow_images_from_data( # for 9 number  \n#   x = val_data_list[[10]]$data   ,   \n#   y = val_data_list[[10]]$label  ,   \n#   train_datagen                  ,   \n#   shuffle = TRUE                 ,   \n#   seed = 9487                    ,   \n#   batch_size = 1 \n# )\n\n\nThe following code is responsible for generating pairs of data samples for one-shot learning, where half of the pairs are from the same class (positive) and the other half are from different classes (negative). It does so by selecting classes and fetching data samples from their corresponding generators. The following code is to create a data generator that generates pairs of data samples and their associated similarity labels for training a siamese neural network.\n\n\n# # creating sample pairs from the same and different classes\n# train_generator_list <- list(\n#   train_0_generator ,\n#   train_1_generator ,\n#   train_2_generator ,\n#   train_3_generator ,\n#   train_4_generator ,\n#   train_5_generator ,\n#   train_6_generator ,\n#   train_7_generator ,\n#   train_8_generator ,\n#   train_9_generator \n# )\n# \n# val_generator_list <- list(\n#   val_0_generator   ,\n#   val_1_generator   ,\n#   val_2_generator   ,\n#   val_3_generator   ,\n#   val_4_generator   ,\n#   val_5_generator   ,\n#   val_6_generator   ,\n#   val_7_generator   ,\n#   val_8_generator   ,\n#   val_9_generator \n# )\n# \n# join_generator <- function(train_generator_list, batch) { \n#   function() { \n#     batch_left  <- NULL \n#     batch_right <- NULL \n#     similarity  <- NULL \n#       for( i in seq_len(batch)) { # i = 1 \n#           if( i <= ceiling(batch/2)) { # front half\n#             grp_same    <- sample(seq_len(num_classes), 1) # randomly sampling one class\n#             # combining array vertically\n#             batch_left  <- abind(batch_left, generator_next(generator_list[[grp_same]])[[1]], along = 1) \n#             batch_right <- abind(batch_right, generator_next(generator_list[[grp_same]])[[1]], along = 1)\n#             similarity  <- c(similarity, 1) # 1 : from the same number\n#             # par(mar = c(0,0,4,0))\n#             # plot(as.raster(batch_left[21,,,]))\n#             # title(batch_left[[2]])\n#           } else { # after half \n#             grp_diff    <- sort(sample(seq_len(num_classes) , 2)) \n#             batch_left  <- abind(batch_left, generator_next(generator_list[[grp_diff[1]]])[[1]], along = 1) \n#             batch_right <- abind(batch_right, generator_next(generator_list[[grp_diff[2]]])[[1]], along = 1) \n#             similarity  <- c( similarity , 0 ) # 0 : from the differnet number\n#           } \n#       } \n#     return(list(list(batch_left, batch_right), similarity)) \n#   } \n# }\n# \n# train_join_generator   <- join_generator( train_generator_list, train_batch )\n# val_join_generator     <- join_generator( val_generator_list  , val_batch   )\n\n\n2.3 Building and training a model\nthe siamese architecture\nIn one-shot learning, the model is trained to recognize new objects or classes with only a single example per class. There are several architectures of one-shot learning, including Siamese, matching, and prototypical networks.\nSiamese Networks: Siamese networks involve training a neural network to learn a similarity metric between pairs of input examples. This allows the network to distinguish between similar and dissimilar instances, making it suitable for one-shot learning tasks in conversion ecology, such as species recognition, identifying plant diseases.\nMatching Networks: Matching networks combine the concepts of attention mechanisms and recurrent networks to make predictions based on a context set of examples. These networks learn to weigh the importance of each sample in the context when making predictions for a new instance.\nPrototypical Networks: Prototypical networks learn a prototype representation for each class based on a few examples. During testing, new samples are compared to these prototypes to make predictions.\nWe build simple convolution as conv_base and let two images use the same conv_base model which share the same weight (see the figure).\n\nThe architecture of a simple siamese\n\nbuilding model with siamese\nThe code for building the one-shot learning with siamese is as follows.\n\n\n# left_input_tensor      <- layer_input(shape = list(shape_size, shape_size, 1), name = \"left_input_tensor\")\n# right_input_tensor     <- layer_input(shape = list(shape_size, shape_size, 1), name = \"right_input_tensor\")\n# \n# conv_base              <- keras_model_sequential()           %>%\n#   layer_flatten(input_shape=list(shape_size, shape_size, 1)) %>%\n#   layer_dense(units = 128, activation = \"relu\", name='fc1')  %>%\n#   layer_dropout(rate = 0.1, name='dropout1')                 %>%\n#   layer_dense(units = 128, activation = \"relu\", name='fc2')  %>% \n#   layer_dropout(rate = 0.1, name='dropout2')                 %>%\n#   layer_dense(units = 128, activation = \"relu\", name='fc3')\n# \n# left_output_tensor     <- left_input_tensor  %>%   \n#                           conv_base  \n# \n# right_output_tensor    <- right_input_tensor %>%   \n#                           conv_base  \n# \n# L1_distance <- function(tensors) { # build keras backend's function  \n#   c(x,y) %<-% tensors   \n#   return( k_abs( x - y ) ) \n# }       \n# \n# L1_layer    <- layer_lambda( object = list(left_output_tensor,right_output_tensor) , # To build self define layer, you must use layer_lamda                                \n#                              f = L1_distance                              \n#                            )   \n# \n# prediction  <- L1_layer%>%                \n#                layer_dense( units = 1 , activation = \"sigmoid\" )  \n# \n# model       <- keras_model( list(left_input_tensor,right_input_tensor), prediction)\n\n\ntraining the model\nDuring training, the model is exposed to pairs of examples. For each pair, one example is treated as the “query” example, and the other is treated as a “support” or “reference” example. The model learns to differentiate between similar and dissimilar pairs. It learns to embed the examples so that similar examples are close in the embedding space and distinct examples are far apart. The learning rate (1e-5) will lead to slowly optimize progress, so we suggest use 1e-3 as our learning rate. Below is comparison, you will find 1e-3 is learning faster than 1e-5 more.\n\n\n# model %>% compile(\n#   loss      = \"binary_crossentropy\",\n#   optimizer = optimizer_rmsprop(learning_rate = 1e-3),\n#   metrics   = c(\"accuracy\")\n# )\n# \n# history <- model %>% fit_generator(\n#   train_join_generator,\n#   steps_per_epoch = 100,\n#   epochs = 40,\n#   validation_data = val_join_generator,\n#   validation_steps = 50\n# )\n# \n# plot(history)\n\n\n2.4 Verifing with test data\nSame number match\nAfter training, the model’s performance is evaluated on new, unseen examples. To make predictions, the model typically calculates distances or similarities between the embeddings of the query example and the support examples. The class associated with the closest support example is predicted as the class for the query example.\n\n\n# # same number\n# mnist_number_left  <- 8\n# filter_idx_left    <- sample( which( test_labels == mnist_number_left  ) , 1 )\n# img_input_left     <- test_images[filter_idx_left ,,]/255\n# mnist_number_right <- 8\n# filter_idx_right   <- sample( which( test_labels == mnist_number_right ) , 1 )\n# img_input_right    <- test_images[filter_idx_right,,]/255\n# img_input_left     <- array_reshape(img_input_left , c(1, shape_size, shape_size, 1))\n# img_input_right    <- array_reshape(img_input_right, c(1, shape_size, shape_size, 1))\n# \n# similarity         <- model %>% predict(list(img_input_left,img_input_right))\n# par(mar = c(0,0,4,0))\n# plot( as.raster( abind(img_input_left[1,,,] ,\n#                        img_input_right[1,,,],\n#                        along = 2\n#                       ) \n#                ) \n# )\n# title( paste0( test_labels[filter_idx_left] , \" v.s \" , test_labels[filter_idx_right] , \" , similarity : \" , round(similarity,3) ) )\n\n\nDifferent number match\n\n\n# # different number\n# mnist_number_left  <- 8\n# filter_idx_left    <- sample( which( test_labels == mnist_number_left  ) , 1 )\n# img_input_left     <- test_images[filter_idx_left ,,]/255\n# mnist_number_right <- 7\n# filter_idx_right   <- sample( which( test_labels == mnist_number_right ) , 1 )\n# img_input_right    <- test_images[filter_idx_right,,]/255\n# img_input_left     <- array_reshape(img_input_left , c(1, shape_size, shape_size, 1))\n# img_input_right    <- array_reshape(img_input_right, c(1, shape_size, shape_size, 1))\n# \n# similarity         <- model %>% predict(list(img_input_left,img_input_right))\n# par(mar = c(0,0,4,0))\n# plot( as.raster( abind(img_input_left[1,,,] ,\n#                        img_input_right[1,,,],\n#                        along = 2\n#                       ) \n#                ) \n#     )\n# title( paste0( test_labels[filter_idx_left] , \" v.s \" , test_labels[filter_idx_right] , \" , similarity : \" , round(similarity,3) ) )\n\n\n3. Import things of deep learning\n3.1 Difference between ANN and CNN\nAs the full code for mnist recolonization, olease visit the site. Here we just mention the import things to be paid.\nLoading the data\nThe dataset can be uploaded from the keras package, and also from local computer. Here we upload it from local computer by performing the following code.\n\n\n\nAfter that, we should know the structure of the data and may need to do preprocessing thing. Here is the code for the checking and pre-processing data.\n\n\n# x_train <- mnist$train$x\n# y_train <- mnist$train$y\n# x_test <- mnist$test$x\n# y_test <- mnist$test$y\n# # dim(x_train)\n\n\nPre-processing for ANN and CNN\nThe x data is a 3-d array (images,width,height) of grayscale values. We convert the 3-d arrays into the 2-d matrices by reshaping width and height into a single dimension (28x28 images are flattened into 784 vectors). The 2-d representation is used for fully connected neural networks or multilayer perceptrons (MLPs) as the input layer typically expects a 2-d matrix where each row is a training sample. Then, we convert the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1.\n\n\n# # for ANN algorithm\n# # reshape\n# x_train_a <- array_reshape(x_train, dim = c(nrow(x_train), 784))\n# x_test_a <- array_reshape(x_test, dim = c(nrow(x_test), 784))\n# # rescale\n# x_train_a <- x_train_a / 255\n# x_test_a <- x_test_a / 255\n\n\nWe convert the x_train into a 4-d tensor with dimensions (nrow(x_train), 28, 28, 1). The nrow(x_train) represents the number of training samples. It retains the original 2-d spatial structure of the images (28x28), but it adds an extra dimension at the end. This additional dimension is often used for color channels (e.g., 1 for grayscale images, 3 for RGB images). It’s a common practice to have this 4-d shape to make the input compatible with CNNs that expect 4-d input tensors.\n\n\n# # for CNN algorithm\n# x_train_c <- array_reshape(x_train, dim = c(nrow(x_train), 28, 28, 1))\n# x_test_c <- array_reshape(x_test, dim = c(nrow(x_test), 28, 28, 1))\n# # rescale\n# x_train_c <- x_train_c / 255\n# x_test_c <- x_test_c / 255\n\n\nThe y data is an integer vector with values ranging from 0 to 9. For both ANN and CNN, we use one-hot encoding to encode the vectors into binary class matrices using the Keras to_categorical() function.\n\n\n# y_train <- to_categorical(y_train, 10)\n# y_test <- to_categorical(y_test, 10)\n\n\nModel difference between ANN and CNN\nThe core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For ANN, the first layer specifies the shape of the input data (a length 784 numeric vector). The final layer outputs a length 10 numeric vector using a softmax activation function.\n\n\n# model <- keras_model_sequential() \n# model %>% \n#   layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>% \n#   layer_dropout(rate = 0.4) %>% \n#   layer_dense(units = 128, activation = 'relu') %>%\n#   layer_dropout(rate = 0.3) %>%\n#   layer_dense(units = 10, activation = 'softmax')\n# summary(model)\n\n\nFor CNN, the input_shape has 4-d. Its model structure is as follows.\n\n\n# model <- keras_model_sequential() \n# model %>%   \n#   layer_conv_2d(filters = 32, kernel_size = c(3, 3), padding = 'same',  input_shape = c(28, 28, 1)) %>%\n#   layer_activation('relu') %>%\n#   # layer_max_pooling_2d(pool_size=c(2, 2), strides=c(2, 2)) %>%\n#   layer_conv_2d(filters = 16, kernel_size = c(2, 2), dilation_rate = 1, activation = 'softplus', padding = 'same') %>%\n#   layer_max_pooling_2d(pool_size=c(2, 2)) %>%\n#   layer_flatten() %>%\n#   layer_dense(1000, activation = 'relu') %>%\n#   layer_dropout(0.5) %>%\n#   layer_dense(10, activation = 'softmax')\n# summary(model)\n\n\nNext, we compile the model with appropriate loss function, optimizer, and metrics, and use the fit() function to train the model for 30 epochs using batches of 128 images. For ANN, using x_train_a to fit the model.\n\n\n# # for ANN by feeding x_train_a\n# model %>% compile(\n#   loss = 'categorical_crossentropy',\n#   optimizer = optimizer_rmsprop(),\n#   metrics = c('accuracy')\n# )\n# \n# history <- model %>% fit(\n#   x_train_a, y_train, \n#   epochs = 30, batch_size = 128, \n#   validation_split = 0.2\n# )\n# \n# plot(history)\n\n\nFor CNN, feeding x_train_c to fit the model.\n\n\n# for CNN by feeding x_train_c\n# model %>% compile(\n#   loss = 'categorical_crossentropy',\n#   optimizer = optimizer_rmsprop(),\n#   metrics = c('accuracy')\n# )\n# \n# history <- model %>% fit(\n#   x_train_c, y_train, \n#   epochs = 10\n# )\n# \n# plot(history)\n\n\nEvaluate the model’s performance on the test data and predictions on new data.\n\n\n# model %>% evaluate(x_test_a, y_test)\n# model %>% predict(x_test_a)\n\n\n3.2 keras generators, Callback and Tensorboard\nAs usual, the training data are too large to fit into memory. So we can use generators to read data, preprocess and eventually feed them into model for training. generator in R is to define a function within a function, which is well documented in the website and the website.\nSampling generator\nwe can define a sampling generator, which serves as pre-processing pipelines – linking raw data to our expected data format by doing sampling, re-scaling, re-shaping and one-hot encoding.\n\n\n# library(keras)\n# np = reticulate::import('numpy') # converting data to numpy type\n# \n# # Load the MNIST dataset\n# mnist <- dataset_mnist()\n# x_train <- mnist$train$x\n# y_train <- mnist$train$y\n# \n# # Sample size and indices\n# sample_size <- 100  # Adjust as needed\n# sample_indices <- sample(1:nrow(x_train), sample_size, replace = FALSE)\n# \n# # Create a data generator with preprocessing\n# mnist_generator <- function(batch_size, sample_indices, x_data, y_data) {\n#   function() {\n#     batch_indices <- sample(sample_indices, batch_size, replace = TRUE)\n#     x_batch <- x_data[batch_indices,, , drop = FALSE] / 255\n#     y_batch <- to_categorical(as.numeric(y_data[batch_indices]), 10)\n#     \n#     # Convert to numpy arrays\n#     x_np <- np$array(x_batch)\n#     y_np <- np$array(y_batch)\n#     \n#     list(x = x_np, y = y_np)\n#   }\n# }\n# \n# # Define the ANN model\n# model <- keras_model_sequential() %>%\n#   layer_flatten(input_shape = c(28, 28, 1)) %>%\n#   layer_dense(units = 128, activation = 'relu') %>%\n#   layer_dense(units = 64, activation = 'relu') %>%\n#   layer_dense(units = 10, activation = 'softmax')\n# \n# model %>% compile(\n#   optimizer = 'adam',\n#   loss = 'categorical_crossentropy',\n#   metrics = c('accuracy')\n# )\n# \n# # Define the batch size and number of epochs\n# batch_size <- 32\n# epochs <- 10  # Adjust as needed\n# \n# # Train the model using the generator\n# history <- model %>% fit_generator(\n#   generator = mnist_generator(batch_size, sample_indices, x_train, y_train),\n#   steps_per_epoch = sample_size / batch_size,\n#   epochs = epochs\n# )\n# \n# # Print training history\n# print(history)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWritting callbacks\nCallbacks are used to control the training process, such as saving model, early stop and reducing learning rate. Here’s an example that includes a sampling generator in the chunk along with the callbacks for model checkpointing, early stopping, and reducing learning rate.\n\n\n# Load necessary libraries\n# library(keras)\n# library(reticulate)\n# np = reticulate::import('numpy')\n# # Load the MNIST dataset\n# mnist <- dataset_mnist()\n# x_train <- mnist$train$x\n# y_train <- mnist$train$y\n# x_test <- mnist$test$x\n# y_test <- mnist$test$y\n#\n# # Convert data to numpy arrays\n# x_train_np <- np$array(x_train / 255)\n# y_train_np <- np$array(to_categorical(y_train, 10))\n# x_test_np <- np$array(x_test / 255)\n# y_test_np <- np$array(to_categorical(y_test, 10))\n#\n# # Function to define a simple model\n# define_model <- function() {\n#   model <- keras_model_sequential() %>%\n#     layer_flatten(input_shape = c(28, 28, 1)) %>%\n#     layer_dense(units = 128, activation = 'relu') %>%\n#     layer_dense(units = 64, activation = 'relu') %>%\n#     layer_dense(units = 10, activation = 'softmax')\n#\n#   model %>% compile(\n#     optimizer = 'adam',\n#     loss = 'categorical_crossentropy',\n#     metrics = c('accuracy')\n#   )\n#\n#   return(model)\n# }\n#\n# # Create the model\n# model <- define_model()\n#\n# # Train the model using the fit function\n# history <- model %>% fit(\n#   x = x_train_np,\n#   y = y_train_np,\n#   epochs = 20,\n#   batch_size = 32,\n#   validation_data = list(x_test_np, y_test_np),\n#   callbacks = list(\n#     callback_model_checkpoint(\"model_checkpoint.h5\", save_best_only = TRUE),\n#     callback_early_stopping(monitor = \"val_loss\", patience = 3)\n#   )\n# )\n#\n# # Print training history\n# print(history)\n\n\nTraining visualization\nThere are a number of tools available for visualizing the training of Keras models, including: 1) A plot method for the Keras training history returned from fit(); 2) Real time visualization of training metrics within the RStudio IDE; 3) Integration with the TensorBoard visualization tool included with TensorFlow.\nPlotting History\nThe Keras’s fit() method returns an R object containing the training history, including the value of metrics at the end of each epoch. You can plot the training metrics by epoch using the plot() method.\nHere we compile and fit a model with the “accuracy” metric.\n\n\n# library(keras) # loading the package for data and modelling\n# library(abind) # operating multidimensional arrays, which are often expressed any image.\n# mnist <- dataset_mnist(\"/home/tank/Desktop/ecodatasci/images/mnist.npz\")\n# x_train <- mnist$train$x\n# y_train <- mnist$train$y\n# x_test <- mnist$test$x\n# y_test <- mnist$test$y\n\n# # for ANN algorithm\n# # reshape\n# x_train_a <- array_reshape(x_train, dim = c(nrow(x_train), 784))\n# x_test_a <- array_reshape(x_test, dim = c(nrow(x_test), 784))\n# # rescale\n# x_train_a <- x_train_a / 255\n# x_test_a <- x_test_a / 255\n# model <- keras_model_sequential()\n# model %>%\n#   layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%\n#   layer_dropout(rate = 0.4) %>%\n#   layer_dense(units = 128, activation = 'relu') %>%\n#   layer_dropout(rate = 0.3) %>%\n#   layer_dense(units = 10, activation = 'softmax')\n# summary(model)\n# # for ANN by feeding x_train_a\n# model %>% compile(\n#   loss = 'categorical_crossentropy',\n#   optimizer = optimizer_rmsprop(),\n#   metrics = c('accuracy')\n# )\n# history <- model %>% fit(\n#   x_train_a, y_train, \n#   epochs = 30, batch_size = 128, \n#   validation_split = 0.2\n# )\n# \n# plot(history)\n# model %>% evaluate(x_test_a, y_test)\n# model %>% predict(x_test_a)\n\n# # for CNN algorithm\n# x_train_c <- array_reshape(x_train, dim = c(nrow(x_train), 28, 28, 1))\n# x_test_c <- array_reshape(x_test, dim = c(nrow(x_test), 28, 28, 1))\n# # rescale\n# x_train_c <- x_train_c / 255\n# x_test_c <- x_test_c / 255\n# y_train <- to_categorical(y_train, 10)\n# y_test <- to_categorical(y_test, 10)\n# model <- keras_model_sequential()\n# model %>%\n#   layer_conv_2d(filters = 32, kernel_size = c(3, 3), padding = 'same',  input_shape = c(28, 28, 1)) %>%\n#   layer_activation('relu') %>%\n#   # layer_max_pooling_2d(pool_size=c(2, 2), strides=c(2, 2)) %>%\n#   layer_conv_2d(filters = 16, kernel_size = c(2, 2), dilation_rate = 1, activation = 'softplus', padding = 'same') %>%\n#   layer_max_pooling_2d(pool_size=c(2, 2)) %>%\n#   layer_flatten() %>%\n#   layer_dense(1000, activation = 'relu') %>%\n#   layer_dropout(0.5) %>%\n#   layer_dense(10, activation = 'softmax')\n# summary(model)\n# \n# model %>% compile(\n#   loss = 'categorical_crossentropy',\n#   optimizer = optimizer_rmsprop(),\n#   metrics = c('accuracy')\n# )\n# \n# history <- model %>% fit(\n#   x_train_c, y_train,\n#   epochs = 10, batch_size = 128, \n#   validation_split = 0.2\n# )\n# \n# plot(history)\n\n\nTensorboard\nTensorboard is the UI view to compare different models as well as the model structure visualization. To launch your tensorboard, type this in your terminal. Beyond just training metrics, TensorBoard has a wide variety of other visualizations available including the underlying TensorFlow graph, gradient histograms, model weights, and more. TensorBoard also enables you to compare metrics across multiple training runs.\n\n\n# # launch TensorBoard\n# tensorboard(\"logs/run_a\")\n# \n# # fit the model with the TensorBoard callback\n# history <- model %>% fit(\n#   x_train, y_train,\n#   batch_size = batch_size,\n#   epochs = epochs,\n#   verbose = 1,\n#   callbacks = callback_tensorboard(\"logs/run_a\"),\n#   validation_split = 0.2\n# )\n# history <- model %>% fit(\n#   x_train, y_train,\n#   batch_size = 128,\n#   epochs = 10,\n#   verbose = 1,\n#   callbacks = callback_tensorboard(\"logs/run_a\"),\n#   validation_split = 0.2\n# )\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2023-11-13T15:40:59+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-classic-machine-learning/",
    "title": "Lesson 1: Classic machine learning",
    "description": "The last few years have seen a surge of interest in applying powerful machine learning tools to challenging problems in ecology. Our goal in this work is to introduce ecologically useful ML-based algorithms.",
    "author": [],
    "date": "2023-11-01",
    "categories": [],
    "contents": "\n\nContents\n1. From statistics to machine learning\n2. Machine learning and its main types\n3. Training models with R packages\n3.1 Data collection and importing\n3.2 Exploratory Data Analysis (EDA)\n3.3 Data Preprocessing\n3.4 Model training and Evaluation\n\n4. other learning resoures\n\n1. From statistics to machine learning\nLinear regression is frequently used in statistical data analysis, i.e., according to least squares, you can calculate its coefficient and intercept. For more details, please check the book. The model performance is examined by \\(R^2\\), and the significance for \\(R^2\\). For details, see the book.\n.\nLinear regression is also achieved via a machine learning algorithm. That is, gradient descent (GD). The operation of GD works by starting with random values for each coefficient. The sum of the squared errors are calculated for each pair of input and output values. A learning rate is used as a scale factor and the coefficients are updated in the direction towards minimizing the sum square errors. The process is repeated until a minimum sum squared error is achieved or no further improvement is possible.\nAll machine learning models are based on GD algorithms, which are different from statistical methods.\n2. Machine learning and its main types\nThe two main paradigms of ML are supervised and unsupervised learning. Supervised learning is a subfield of ML concerned with finding a function f such that \\(\\hat{y} = f(x)\\) where x is an input sample vector, y is an output sample vector, and \\(\\hat{y}\\) is a predictor of y. Common supervised learning tasks include classification and regression. Unsupervised learning aims to find a function g which transforms an input sample x to a representation z in order to reveal underlying information about the input sample. A common unsupervised learning task is clustering.\nIn machine learning algorithms, a parameterisable function \\(f_{θ}\\) is often defined. The parameters θ of the function can then be learned through an iterative process of updating the parameters and evaluating the performance of the function. This process is known as optimization or training; these training algorithms often rely on a function \\(L(y, \\hat{y})\\) which quantifies how incorrect a prediction is compared to the target vector. This is usually known as the cost, error, or loss function, and is chosen depending on the task in hand.\nDuring optimization, parameters are adjusted according to training data. In the case of supervised learning, training data comprises pairs of input and output vectors, each taking the form (x, y). The algorithm will be shown each data sample multiple times. The number of times an algorithm “sees” the entire set of training data is known as an epoch, and is used as a measure of how much an algorithm has been trained. In some circumstances, an algorithm can perform well on the training data but does not perform well on new data. This is known as overfitting, and occurs when the algorithm has learned to predict the target output of each sample in the training data by random noise in the input features, rather than by the important underlying variables.\nOverfitting can be detected by splitting the training data into three sets: training, validation, and test. Under this split, the algorithm is trained on the training set, and after each epoch is evaluated on the validation set. When the performance on the validation set does not increase, the algorithm has stopped learning useful properties and has begun to overfit. The algorithm can then be stopped -known as early-stopping - and evaluated on the unseen test set to give a true indication of the algorithm’s performance. The general configuration of the function f is usually governed by hyperparameters, which - unlike parameters - are fixed and are not adjusted during training.\nML algorithms are attractive options for solving some problems, because the learned functions \\(f_{θ}\\) are derived directly from the training data without intervention. This makes ML algorithms particularly useful on complex problems for which it is difficult or near-impossible to manually define suitable functions. However, the usefulness of ML is not limited to predictive tasks; after training the learned function can also be interpreted to yield useful information about the data.\n3. Training models with R packages\nBelow, we’ll examine fundamental machine learning ideas, methods, and a step-by-step procedure of machine learning model developments by utilizing Caret package. Please check this website for details. In this section, we need the libraries, including:\nggplot2: for interactive graphs and visualization.\nggpubr: for making plot beautiful along with that of ggplot2.\nreshape: for melting dataset.\ncaret: providing many machine learning algorithms.\n\n\n# # To load all necessary packages\n# library(ggplot2)\n# #library(ggpubr) \n# library(reshape)\n# library(caret)\n\n\nWe will walk through each step of implementing Caret package in this part. The general steps to be followed in any Machine learning project are:\n3.1 Data collection and importing\nNext, we will import our data to a R environment.\n\n\n# # Dataset\n# data(\"iris\")\n#   \n# # To display the first five rows of our data\n# head(iris)\n\n\n3.2 Exploratory Data Analysis (EDA)\nUnderstanding and assessing the data you have for your project is one of the important steps in the modeling preparation process. This is accomplished through the use of data exploration, visualization, and statistical data summarization with a measure of central tendencies. You will gain an understanding of your data during this phase, and you will take a broad view of it to get ready for the modeling step.\n\n\n# Summary statistics of data\n# summary(iris)\n\n\nVisualizing the outliers by using boxplot. As we use ggplot2 we will take numerical variables by subsetting the entire of it. Using of reshape package we melt the data and plot it to check for the presence of any outliers.\n\n\n# df <- subset(iris, select = c(Sepal.Length, \n#                               Sepal.Width, \n#                               Petal.Length, \n#                               Petal.Width))\n# # plot and see the box plot of each variable\n# ggplot(data = melt(df), \n#        aes(x=variable, y=value)) + \n#         geom_boxplot(aes(fill=variable))\n\n\nLet’s now use a histogram plot to visualize the distribution of our data’s continuous variables.\n\n\n# a <- ggplot(data = iris, aes(x = Petal.Length)) +\n#     geom_histogram( color = \"red\", \n#                    fill = \"blue\", \n#                    alpha = 0.01) + geom_density()\n#   \n# b <- ggplot(data = iris, aes(x = Petal.Width)) +\n#     geom_histogram( color = \"red\", \n#                    fill = \"blue\", \n#                    alpha = 0.1) + geom_density()\n# c <- ggplot(data = iris, aes(x = Sepal.Length)) +\n#     geom_histogram( color = \"red\", \n#                    fill = \"blue\", \n#                    alpha = 0.1) + geom_density()\n#   \n# d <- ggplot(data = iris, aes(x = Sepal.Width)) +\n#     geom_histogram( color = \"red\", \n#                    fill = \"blue\", \n#                    alpha = 0.1) +geom_density()\n#   \n# #ggarrange(a, b, c, d + rremove(\"x.text\"), \n# #          labels = c(\"a\", \"b\", \"c\", \"d\"),\n# #          ncol = 2, nrow = 2)\n\n\nNext, we will move to the Data Preparation phase of our machine learning process. Before that, lets split our dataset into train, test and validation partition.\n\n\n# # Create train-test split of the data \n# limits <- createDataPartition(iris$Species, \n#                               p=0.80, \n#                               list=FALSE)\n#   \n# # select 20% of the data for validation\n# testiris <- iris[-limits,]\n#   \n# # use the remaining to training and testing the models\n# trainiris <- iris[limits,]\n\n\n3.3 Data Preprocessing\nThe quality of our good predictions from the model depends on the quality of the data itself, data preprocesing is one of the most important steps in machine learning. We can see from the box plot that there are outliers in our data, and the histogram also shows how skewed the data is on the right and left sides. We shall thus eliminate those outliers from our data.\n\n\n# Q <- quantile(trainiris$Sepal.Width, \n#               probs=c(.25, .75), \n#               na.rm = FALSE)\n\n\nAfter obtaining the quantile value, we will additionally compute the interquartile range in order to determine the upper and lower bound cutoff values. Then, we eliminate the outliers.\n\n\n# # Code to calculate the IQR, upper and lower bounds\n# iqr <- IQR(trainiris$Sepal.Width)\n# up <-  Q[2]+1.5*iqr \n# low<- Q[1]-1.5*iqr\n\n# # Elimination of outliers by using of iqr\n# normal <- subset(trainiris, \n#                  trainiris$Sepal.Width > (Q[1] - 1.5*iqr) \n#                  & trainiris$Sepal.Width < (Q[2]+1.5*iqr))\n# normal\n\n\nBy using a boxplot, we can additionally see the outliers that were eliminated from the data.\n\n\n# # boxplot using cleaned dataset\n# boxes <- subset(normal, \n#                 select = c(Sepal.Length, \n#                            Sepal.Width, \n#                            Petal.Length, \n#                            Petal.Width))\n# ggplot(data = melt(boxes), \n#        aes(x=variable, y=value)) + \n#         geom_boxplot(aes(fill=variable))\n\n\n3.4 Model training and Evaluation\nIt’s time to use the clean data to create a model. We don’t have a specific algorithm in mind, Let’s compare LDA and SVM for practical purposes and choose the best one. For accuracy and prediction across all samples, we will employ 10-fold cross validation.\n\n\n# # crossvalidation set to 10\n# crossfold  <- trainControl(method=\"cv\", \n#                            number=10, \n#                            savePredictions = TRUE)\n# metric <- \"Accuracy\"\n\n\nLet’s start training model with Linear Discriminant Analysis.\n\n\n# # Set a random seed to 42\n# set.seed(42) \n# fit.lda <- train(Species~., \n#                  data=trainiris, \n#                  method=\"lda\", \n#                  metric=metric, #\n#                  trControl=crossfold)\n# print(fit.lda)\n\n\nWe can also use SVM model for the training.\n\n\n# set.seed(42)\n# fit.svm <- train(Species~., \n#                  data=trainiris, \n#                  method=\"svmRadial\", \n#                  metric=metric,\n#                  trControl=crossfold)\n# print(fit.svm)\n\n\nThe results show that both algorithms functioned admirably with only minor variations. Although the model can be tuned to improve its accuracy accurate, for the purposes of this lesson, let’s stick with LDA and generate predictions using test data.\n\n\n# # prediction on test data\n# predictions <- predict(fit.lda, testiris)\n# confusionMatrix(predictions, testiris$Species)\n\n\nAccording to the summary of our model above, We see that the prediction performance is poor; this may be because we neglected to consider the LDA algorithm’s premise that the predictor variables should have the same variance, which is accomplished by scaling those features. We won’t deviate from the topic of this lesson because we are interested in developing machine learning utilizing the Caret module in R.\n4. other learning resoures\nHere is a concise guide to machine learning techniques for ecological data. This practical guide to machine learning includes explaining and exploring different machine learning techniques, from CARTs to GBMs, using R.\n\n\n\n",
    "preview": {},
    "last_modified": "2023-11-01T09:59:08+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-deep-learning-as-data-driven-methods/",
    "title": "Lesson 3: Deep Learning as Data-driven Methods",
    "description": "The immediate aim of this section is to develop a data-driven machine learning algorithm to predict which interactions are missing from ecological networks, and to explore ways in which ecological insight can be extracted from the algorithm. In particular, we introduce key concepts and terminology of data-driven models.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\n\nContents\n1. What are neural networks and how do they learn?\n2. Appplications of deep learning to ecology and evolution\n2.1 Automated species identification\n2.2 Environmental monitoring and modeling\n2.3 Behavioral studies\n2.4 Genomics, population genetics, and phylogenetics\n\n\nEcology and evolutionary biology investigate complex patterns and processes. A mathematical toolkit has been necessary to describe and explain fundamental components of organic evolution and ecological interactions. This wealth of data is driving the development of analytic tools that can provide new understanding, greater efficiency, and ease of use. Likelihood-based mechanistic approaches designed to consider many variables can be so computationally expensive that they can no longer be applied to data routinely generated in modern studies. A promising alternative is likelihood-free inference, one example of which is machine learning. The goal of machine learning is to find a model that performs well at making predictions from the data. This contrasts with likelihood-based methods, which assume the model generating the data is known. More recently machine learning has seen a dramatic surge in popularity\nwith a slew of new algorithms and applications.\nOne of the approaches rapidly gaining popularity is deep learning. Deep learning relies on multilayered, connected processing units (artificial neural networks or ANNs). The successes of deep learning were possible because of a major advantage of deep learning over classical machine learning approaches. Classical machine learning requires that important data features are identified using expert domain knowledge. Neural networks can automatically discover the most important data features and patterns relevant for the task. Researchers are now beginning to apply deep learning to problems across ecology and evolutionary biology, from community science projects and environmental monitoring through sequencing equipment output processing, to population genetics\nand phylogenetic inference.\n1. What are neural networks and how do they learn?\nHere describe what artificial neural networks are and how they are used as inference tools (Box 1).\n\n\n\nBox 1: Common neural network architectures\n\n\nArtificial Neural Networks(ANNs) is a group of multiple perceptrons/ neurons at each layer. Neurons can be connected to other neurons in different layers but not within the same layer. In the simplest form, a neural network has one input layer, at least one intermediate or hidden layer, and an output layer. The trainable network parameters consist of biases and weights. Each node has a bias value (b), which determine how easy it is for it to “fire”. Each connection has a weight value (W) which represents connection strength. Each node also has an activation function (f), for example sigmoid\nfunction. Given some input (x), the so-called feedforward output (y) of a node is determined by a simple equation: \\(y = f(W × x + b)\\).\nANN is a Feed-Forward Neural network because inputs are processed only in the forward direction. Recurrent neural networks is to add loops to information flow. Information flows from the input to the output of the network but it can flow back from the output to the input of the hidden layer through recurrent weights.\n\n\n\nHowever, simple RNNs such as the one shown in the figure are difficult to train because weights in these networks can quickly diverge during training. More advanced RNN, such as Long Short-Term Memory networks (LSTMs) or Gated Recurrent Units (GRUs), address this problem and are commonly used with time series data. In evolutionary biology, deep learning solutions including GRU have been used to predict recombination landscapes. In the field of ecology. reserchers are trying to use deep learning techonologies for the analysis of remote sensing data. The convolutional neural networks (CNNs) can excel at capturing complex, hierarchical patterns and are the architecture used in most identification and classification problems.\n\n\n\n\nIn mathematical sense, neural networks are simply a function mapping input onto a desired output. This general design is simple, but it makes neural networks\nextraordinarily powerful: a network with information flowing from input to output layer with at least one intermediate layer (i.e. feedforward network) can approximate any continuous function, regardless of its complexity. These approximations can describe pixels of an image, for example, and networks with multiple intermediate layers (deep neural networks) can also learn relationships between them as high-level concepts such as lines, geometric shapes, and even whole scenes.\nANNs learn continuous distributions but their output can represent probabilities of distinct data classes, as well as continuous values. Such networks can thus be used to construct classifiers, which are models distinguishing among discrete categories, as well as regression models, which infer continuous values. But feedforward operations alone do not allow the network to learn or generalize to new data, which is the essence of most ANN applications.\nIn order for an ANN to be a predictive tool, one needs to assess how good predictions are and be able to adjust ANN parameters to improve performance. A measure of how far off the output of the network is is called a loss function. One example of a loss\nfunction is the sum of squares error (SSE), which is simply the sum of differences between each predicted value (y) and the true value (\\(\\overline{y}\\)) squared for absolute value:\n\\[SEE= \\sum_{i = 1}^{n}(y_i - \\overline{y}_i)^2\\]\nThe network also needs a mechanism for finding the set of parameters that minimize the loss function. Once the loss (error) is measured at the output, it has to be traced back across the network to measure how parameters contributed to it. This process is called backpropagation and it uses chain rule calculus to find the derivative (slope) of the loss function with respect to the network’s trainable parameters. The process of increasing or decreasing parameters such that they minimize the derivative of the loss function is called gradient descent. This process is iterative, occurring every time a batch of training data is processed, and collectively referred to as the training loop. When devised correctly, it results in improvement of inference accuracy with each pass of the loop.\nThe fact that ANNs are universal approximators for continuous functions that can be trained makes them powerful predictive tools. This learning scheme is most easily illustrated with an example of supervised learning, where the network is trained on a data set, e.g. images of expert-identified species or methylated vs. unmethylated DNA sequences. Supervised training usually involves splitting data into three subsets:\ntraining, validation, and testing. The validation set is not directly used in training but prediction on it is performed at the end of each training cycle to assess how well the network generalizes outside of the training set. Test set is held back for the final estimate of accuracy.\n2. Appplications of deep learning to ecology and evolution\nIn the sections that follow, we review how deep learning has been applied in ecology and evolution, including species identification and monitoring, ecological and behavioral studies, and population genetics and phylogenetics. We use these examples to showcase the variety of deep learning techniques extending its usage beyond the general picture described above.\n2.1 Automated species identification\nDeep learning enabled breakthroughs in automated image classification, largely possible thanks to CNNs. Image recognition has obvious applications in biology and was\nadopted early for problems of species identification and wildlife monitoring. It is not surprising then that identification or classification of individuals or species from image, video, and sound data is the most common use of deep learning in the field. These efforts already span many taxa, from bacteria, through protozoans, plants to insects and vertebrates, both extant and fossil and at scales ranging from local to global. Intensifying efforts to digitize natural history collections provide troves of\nimage data that can be used for this purpose.\nCamera trap systems and deep learning classifiers are now commonly used for vertebrate wildlife monitoring and systems automating environmental monitoring of aquatic macroinvertebrates are also being developed. Many publications present systems or deep learning models for detecting and identifying pests or crop diseases in agroecosystems or stored agricultural\ncommodities. Despite economic importance and demonstrated potential for crop pest and disease monitoring, at present few non-proprietary systems or open source software\napplications exist. A notable exception is a mobile application system for identifying diseases of cassava plants, one of the most important tropical crops.\nDeep learning has also been applied to identification from audio recordings, including bird and bat sounds, and even wing beats of mosquitoes. Unsurprisingly, the technology has been applied most often to bird calls, where it has been used not only to identify species, but also monitor their abundance. The recently developed BirdNET is a deep neural network capable of identifying North American and European birds from vocalizations in complex soundscapes, available on a variety of platforms, including user-friendly smartphone apps. Most of these studies use audio converted to spectrograms, image representations of sound, to train CNNs as in visual recognition problems.\nGiven its utility for automated identification, deep learning is increasingly used in community science initiatives. Examples include a growing number of mobile phone applications such as plant-focused identification app Pl@ntNet, bird identification tool Merlin or the citizen naturalist portal iNaturalist, as well as a number of more local or taxon-specific guides. Many of these applications crowd-source training data collection and identification verification by users. They improve by periodically re-training their deep learning classifiers as more reliable data is collected.\nMany of these studies employ data handling approaches that increase performance of deep learning classifiers. Several use data augmentation, a technique that relies on altering training data with distortion. These modifications, applied to each data input in each training epoch, effectively increase training set size. Data augmentation is an important strategy for reducing overfitting and almost always results in increased classifier accuracy. By ensuring that the neural network never sees the same input twice, augmentation only partly addresses the fact that acquiring large, human-labeled datasets is a bottleneck for many applications. An alternative approach is to train an initial classifier in a supervised way, using a labeled training set, and then use this reasonably well-performing classifier for adding more images in an unsupervised manner, without human intervention.\nAnother technique ubiquitous in identification and classification tasks is transfer learning. Transfer learning is most commonly accomplished by first training on a different, usually larger and more general dataset than the one assembled for the problem on hand. The resulting network parameters can then be used as the starting point for fine-tuning on the focal dataset. In species recognition from images it is common to use networks pre-trained on large, public datasets of everyday objects such as ImageNet or COCO as illustrated by several of the studies cited above. Using pre-trained networks makes the network learn faster and often results in higher accuracy.\nIn addition to properly assigning a label to an image, termed image classification, a common computer vision problem is to localize objects. Object recognition is a term often used for the combination of the two: drawing a bounding box around an object and predicting its class. Because there may be many objects in an image, this is a more challenging problem. The many proposed solutions involve either extracting candidate regions from images prior to prediction or predicting classes directly on grids of image pixels. Examples are common in agriculture, where object detection has been used to identify and count pests.\nThe deep learning framework allows training several neural networks of the same or varying architectures on one dataset and averaging their predictions. Known as model ensembling, this technique reduces variance in predictions and can improve accuracy. Examples in species identification include Finnish fungi recognition and UK ladybird beetles.\nFinally, deep learning is not limited to considering image pixels alone but can also take advantage of contextual information such as locality or phenology. For example, output can be improved by filtering out\nnonsensical predictions given prior occurrence data. This approach, however, does not jointly consider the available data in a common framework. Neural networks can be trained on multiple data inputs simultaneously and consider them jointly in the final layers. One study used this approach for beetle identification from images and found improvement in accuracy with information about location, date, weather, habitat, and\nuser expertise.\n2.2 Environmental monitoring and modeling\nThe above mentioned approaches to automated identification of species or individuals are also being scaled to ecosystem scale and applied to diversity assessment, conservation, and resource management. Examples using techniques detailed\nin the previous section include detecting and estimating abundance of zooplankton\nand detecting and counting sea turtles and whales using drone and satellite imagery. Other uses combine digital imagery with LiDAR and other remote sensing or geospatial data for mapping of vegetation, forest carbon stock, and the footprint of fishing across the world’s oceans. Similar applications include integrated systems for real-time wildlife monitoring using data from camera traps and microphone and raise the prospect of surveillance of social media posts for illegal animal trade.\nIn addition to classification and mapping of static information, RNNs and similar approaches have been used with temporal ecological data. Examples include predicting\neutrophication, phytoplankton blooms, and benthic invertebrate community dynamics. As mentioned previously, combining inputs from different sources is natural for deep learning and Rammer and Seidl take advantage of this to predict and map future bark beetle outbreaks based on temporal information on climate, vegetation, and past outbreaks. Capinha et al. proposed a generalized approach to classification and prediction from ecological time series data leveraging automated choice of the best network architecture for the task at hand.\nFinally, neural networks are being used to develop more realistic models and simulations of real world patterns and phenomena. Benkendorf and Hawkins found that deep neural networks can be used to generate accurate species distribution models but\nalso noted that other machine learning approaches perform as well or better with limited training data. Strydom et al. designed a system to predict species interactions from co-occurrence data. A study using reinforcement learning investigated how learning to hunt or avoid predators by individual agents influenced predator-prey dynamics.\n2.3 Behavioral studies\nThe study of animal behavior, both in the field and controlled laboratory settings, is another research area of ecology and evolution that is poised to greatly benefit from adoption of deep learning. Recent technological advancements in sensing, monitoring, and automation allow behavioral ecologists to collect and analyze large amounts of data Long-standing challenges in identifying, quantifying, and analyzing animal behavior still limit the ability to fully automate processing of these data, however. Deep learning has the potential to address many of these challenges and it is increasingly being adopted in studies involving identification of individual animals, body posture and movement tracking, and classification of behaviors.\nIn the area of animal body posture, deep learning can provide non-invasive estimation of the position of animals’ body parts from video recordings. Several open-source toolkits have been developed for this purpose, ranging from species-specific solutions, to generic frameworks applicable to any species, some of which offer 3-dimensional and/or multiple animals tracking. In addition to pose estimation,\ndeep learning is also being adopted to enhance the performance of established computer vision methods used to track spatial position of animal detection or the identification of markers, as well as to automatically perform behavioral analysis of spatial trajectories.\nDeep learning can also allow for the identification, classification, and subsequent re-identification of individual animals from camera feeds or traps, both in the wild and in captivity. Usually based on the use of CNNs for image recognition, deep\nlearning can also be combined with other technologies to develop automated\ndata-processing pipelines to collect and label samples bird species. A popular application in this area is face recognition enabling mark-recapture studies for monitoring populations of individuals, their behavior, and social interactions. Examples in the wild include identification of elephants, chimpanzees, right whales and brown bears. Studies performed in captivity have been carried out\non pandas and pigs.\nFinally, deep learning is being applied to automatically detect and classify the behavior of animals from raw data, a crucial step towards overcoming time-consuming and error-prone manual labeling tasks. Largely based on CNNs, a number of different solutions have been developed to recognize and label behaviors from images as well as video and sound recordings. These behavior detection systems can discriminate between behaviors, with the possibility of concurrent behaviors and thus multi-labeling, or be specifically designed to detect binary events (e.g. distinguish whale vocalizations from noise, or rare social changes in otherwise stable insect colonies). In addition to behavior recognition, deep learning solutions are also being devised to predict behavioral measurements that would otherwise require specialized recording devices. For example, Browning et al. used artificial neural networks to predict the diving behavior of seabirds from GPS data alone without specialized time-depth records,\nwhereas Liu et al. used vertical movement sensors alone to predict locomotor energy expenditure of sharks.\n2.4 Genomics, population genetics, and phylogenetics\nA rapidly growing number of studies apply deep learning to study genomes. Deep learning is used in DNA sequencing for translating the raw signal of long-read Oxford Nanopore sequencers into nucleotide calls, outperforming other basecallers. Another example of successful application is variant calling, or identification of small nucleotide polymorphisms and indels in diploid or polyploid genomes. DeepVariant is a tool that converts text file representations of multiple sequences aligned to a reference (read pileups) to images and uses a CNN to predict alternative alleles. Another tool predicts gene copy number variations from high-throughput sequencing reads. Deep learning has been particularly successful in functional and regulatory genomics and has been used for predicting sequence specificity of nucleic acidbinding proteins, methylation status, identification of transcription start sites, predicting expression patterns from genotypes, classification of transposable elements, and more. These applications are not strictly within the purview of ecology and evolution and have been comprehensively reviewed elsewhere.\nDeep learning is a part of a growing trend to apply machine learning to the study of evolution of populations and species. One of the early studies applying neural networks to population genetic data showed them capable of estimating population-scale mutation rates, population sizes and their changes through time, recombination rates,\nand detecting introgressed loci and positive selection on simulated data. That study\ndemonstrated that CNNs are capable of estimating population genetic parameters in scenarios for which likelihood-based methods have yet to be developed, such as accurately inferring recombination rates from read coverage data in autotetraploid genomes. The impressive performance of deep learning for population genetics encouraged recent development of user-friendly tools for inference from empirical data, including selective sweep classification, quantifying selection strength, jointly inferring selection and population size change, and inferring recombination landscapes. Other studies relied on custom approaches to identifying deleterious variants in sorghum and positive selection in SARS-CoV-2. An emerging approach involves combining deep learning with approximate Bayesian computation (ABC). It has been applied to inferring population size change through time, identifying hybridization from pairwise nucleotide divergences, and choosing best-fitting demographic scenarios based on site frequency spectra or SNP data. Most of the above approaches use CNNs, which in their standard formulation are sensitive to permutations. This means that the ordering of chromosomes in the input, for example, is significant for training and prediction. Flagel et al. dealt with this by sorting chromosomes by similarity but network architectures insensitive to input ordering are\nalso being developed.\nDeep learning has also been used for inference and visualization of population structure. Here neural networks are used for dimensionality reduction, similar to\nprincipal component analysis, rather than for solving a classification or regression problem. To achieve this, the authors used variational autoencoders (VAEs), a pair of neural networks that learn efficient representations of data in an unsupervised manner. In this method the encoder network compresses input data into latent variables, while the decoder network attempts reconstructing the original data from those variables. The loss function in this case is a combined measure of how good the reconstruction is and desirable properties of latent variables. The goal was to visualize population structure in a two-dimensional space and so the data were compressed into two variables representing coordinates.\nAs the importance of the spatial component is becoming increasingly highlighted in population genetics, deep learning is also beginning to be used for predicting sample origins based on genetic variation and local-ancestry inference, which aims to identify populations from which a genetic locus descended. This application involves using generative adversarial networks (GANs) to create artificial human genomic sequences of known ancestry.\n\n\n\n",
    "preview": {},
    "last_modified": "2023-10-25T09:38:16+08:00",
    "input_file": {}
  },
  {
    "path": "models/2023-10-15-remote-sensing-data-and-models/",
    "title": "Lesson 4: Remote sensing data and models",
    "description": "Remote sensing is the science of identifying, observing, collecting, and measuring objects without coming into direct contact with them. This can be accomplished through many devices that carry sensors and capture the characteristics of Earth remotely. Sensors on board satellites also record the electromagnetic energy that is reflected or emitted from objects on Earth. They are especially useful for natural resoures and a variety of socio-economic research and applications.",
    "author": [],
    "date": "2023-10-15",
    "categories": [],
    "contents": "\n\nContents\n1. Remote sensing data\n2. Data operations and tools\n2.1 Download data of aoi\n2.2 Merging, cropping and masking\n2.3 Extracting values and computing statistics\n2.4 Storing and exporting results\n\n3. A practical example\n\n1. Remote sensing data\nForest Cover Data\nThis section is adopted from the module. we will primarily work with the Vegetation Continuous Fields (VCF) data provided by the Land Processes Distributed Active Archive Center (LP DAAC), a component of NASA’s Earth Observing System Data and Information System (EOSDIS). The MOD44B Version 6 VCF is a yearly representation of surface vegetation from 2000 to 2020 at 250 m resolution. Each pixel stores a percentage of three ground cover components: percent tree cover, percent non-tree cover, and percent bare.\nThe ground cover percentages are estimates from a machine learning model based on the combination of the Moderate Resolution Imaging Spectroradiometer (MODIS) data and other high resolution data from NASA and Google Earth. The machine learning model incorporates the visible bandwidth as well as other bandwidth such as brightness temperature (from MODIS bands 20, 31, 32).\nThe VCF data utilize thermal signatures and other correlates to distinguish forest and non-forest plantation, which is an improvement compared to the Normalized Differenced Vegetation Index (NDVI). For this use case, VCF also improves on the Global Forest Cover (GFC) data set, another source used to study deforestation, which only provides binary data points. GFC records baseline forest cover in the year 2000 and includes a binary indicator for the year of deforestation for each 30m × 30m pixel. If over 90% of the forest cover was lost in a pixel by a given year, then the pixel is marked as deforested, while a pixel is marked as reforested if the forest cover went from 0 in 2000 to a positive value. The VCF records continuous changes in percent of ground cover components, which provides more details than the GFC data.\nNighttime lights\nThere is a strong correlation between nighttime lights and Gross State Product (GSP) or Gross Domestic Product (GDP) measures, at the national, state and regional levels or even at a more granular resolution. Thus, nighttime light observations can be used as a proxy for economic activity, especially over periods or regions where these data are not available or where the statistical systems are of low quality or when no recent population or economic censuses are available. Similarly, changes in nighttime light intensity can be used by economists as an additional measure of income growth when no other measures of income growth are available.\nProville et al. (2017) examined trends observed by DMSP-OLS in the period 1992-2013 and their correlation with a series of socio-economic indicators. They found the strongest correlations between nighttime lights, electricity consumption, CO2 emissions, and GDP, followed by population, CH4 emissions, N2O emissions, poverty and F-gas emissions.\n2. Data operations and tools\n2.1 Download data of aoi\nIn order to perform data manipulation, we need to attach packages. We are going to use the package luna to download data from MODIS and the packages terra, tidyverse, raster, and sf for data manipulation.\n\n\n\nWe follow thistutorial to get MODIS data with luna. For details of the terra package, please refer to the package manuscript and this tutorial. If you are not familiar with the tidyverse workflow, please refer to the R for Data Science.\nOnce the required packages have been attached, we can access VCF in R. We prefer using R for its ability to download large numbers of files and enable regular, automated updates.\nWe can first use luna to check the list of data products available from MODIS. Since luna can also access data from the LANDSAT and SENTINEL platforms, we add “MOD|MYD|^MCD” to narrow our scope to MODIS data. The printed results below list six products from MODIS.\n\n\n\nThe product name for VCF is MOD44B. We can use the function productInfo to launch the information page of VCF.\n\n\n\nWe can query MODIS and only download a subset of the data. We need to specify the start and end dates and our area of interest (AOI). The date format is “yyyy-mm-dd”. Suppose here we want to subset data from 2010 to 2012.\n\n\n\nIn order to subset your area of interest, you need to provide a “map” to getModis(). This can be obtained from online databases such as the global administrative area database (GADM). You can download map data directly from GADM or you can use R to obtain GADM map data. We will use R below, which requires first installing the package geodata.\n\n\n\nGeographic levels in GADM are defined as:\nlevel 0: National\nlevel 1: State/province/equivalent\nlevel 2: County/district/equivalent\nlevel 3/4: Smaller administrative levels\nFor our example, we are interested in India at the district level. We can download the map of India and its level 2 administrative areas with the following code:\n\n\n\nThe boundary data is downloaded to the path that you specified in the path argument. The downloaded data through gadm() will be in the PackedSpatVector class. If you want to convert it to another class (for example, the sf class, which is easier to work with in R), you can first read it using readRDS(), then convert to a SpatVector via vect() from the terra package, and finally convert it to a sf object.\n\n\n\nThe map we downloaded is at the district level (level 2). Assume our AOI is the state of Odisha. Each row of the data represents a county in Odisha, and the geospatial information for each county is stored in the last column: geometry. We can filter to obtain the boundaries for our AOI, which will return aoi in vector format, stored as a data frame in R.\n\n\n\n\n\n\nNow that we have our AOI as well as time frame, we can filter the MODIS VCF data on these values and see what is available.\n\n\n\nThe products we are going to download are tiled products. For details of tiled products, the tilling system, and the naming convention, please refer to the MODIS overview page. In essence, we will be downloading grids of maps that cover our AOI.\nTo actually download these files from the NASA server, you will need a username and password. Please register on NASA Earth Data if you haven’t done so.\nThe following code will download the files. Replace the path value with the location on your computer where you would like to store these files. Replace the username and password values with your NASA Earth Data credentials from above.\n\n\n\nThe data format from MODIS is HDF and may include sub-datasets. We can use terra to read these files and create raster files. For example,\n\n\n\nWe can find basic information such as the coordinate reference system, number of cells, and resolution from the above output. There are 7 layers in each of the VCF tiled files. We are interested in the percent tree coverage layer.\n\n\n\nA quick plot of the data can be done with the plotRBG() function.\n\n\n\n2.2 Merging, cropping and masking\nSince there are four hdf files in each year for our AOI, we can first merge the four SpatRaster files into one file per year. We’ll use 2010 as an example. We can filter to only include our layer of interest - percent of tree cover - from each hdf file, which can be done by subsetting the output using [[1]] (using 1 because percent tree cover is the first layer in each file).\n\n\n\nBefore we merge these SpatRster objects, it is often a good practice to check their origins and resolutions. merge requires origin and resolution to be the same across objects.\n\n\n\n\n\n\nWe see that origins of these files are slightly different, but all are close to (0, 0). We do not need to worry about these slight differences, as merge will handle them automatically.\n\n\n\nNote: cells with 200% represent water and rivers.\nWe are now ready to crop and mask the raster file to match our AOI. This tutorial explains the difference between cropping and masking.\nTo crop a raster file according to vector data boundaries (eg, our aoi object representing Odisha districts), we first align the coordinate reference systems of our raster file and vector file. Then, use crop(raster data, vector data). To mask, use mask(raster data, vector data). Note that for terra::mask(), the second argument needs to be SpatVector. terra does not support sf objects yet, so we use vect(aoi) to convert our sf object aoi to a SpatVector.\n\n\n\nTo plot our new raster file, we use:\n\n\n\n2.3 Extracting values and computing statistics\nAfter we have cropped and masked the raster file to our AOI, we can extract values for each county in the state of Odisha.\n\n\n\nThe values extracted by terra::extract are stored in a data frame. Note that the ID corresponds to the row number of your vector file (i.e. object aoi in our case). We can then compute statistics based on this data frame. Here we compute several statistics describing the percent of forest cover for each county. Note that cells with 200% represent water and river and should be excluded from calculation.\n\n\n\n2.4 Storing and exporting results\nWith terra you can easily write shape files and several formats of raster files. The main function for writing vector data is writeVector(), while for writing raster data we use writeRaster(). For details, you can refer to this page and the documentation of terra.\n3. A practical example\nWe will replicate some main results in the paper. To access the full replication data and code, check this github repo. We are going to replicate Table 3 in the paper.\nThe research question is whether newly constructed rural roads impact local deforestation. The authors explored this question using two empirical strategies: fuzzy RD and difference-in-difference. In the following sections, we implement the difference-in-difference method and replicate the regression results.\nIn order to run fixed effects models, we will need the fixest package. This tutorial is a good reference for introducing fixest functions.\nData for this exercise was processed and stored in pmgsy_trees_rural_panel.csv, which you can find the through the link to the CSV data in the github repo. Each row of the data frame presents a village in a specific year.\n\n\n\nThe paper estimated the following equation:\n\\[\nForest_{vdt} = β_{1}Award_{vdt} + β_{2}Complete_{vdt} + α_{v} + γ_{dt} + X_{v}⋅V_{t} + η_{vdt}\n\\]\nwhere \\(Forest_{vdt}\\) is forest cover of village \\(v\\) in district \\(d\\) in year \\(t\\). \\(Award_{vdt}\\) is a dummy variable which takes one during the period when the new road is awarded to the village but has not been built. \\(Complete_{vdt}\\) is also a dummy variable which takes one for all years following the completion of a new road to village \\(v\\). \\(α_{v}\\) are village fixed effects, while \\(γ_{dt}\\) are the district-year fixed effects. \\(X_{v}\\) controls some baseline characteristics (e.g. forest cover in 2000, total population) and is interacted with year fixed effects \\(V_{t}\\).\nThere is one more step before we run the regressions. In Stata, which the authors used for their regression, reghdfe removed singleton groups automatically. However, the fixest package currently doesn’t possess this functionality, so for now, we will manually remove these observations.\n\n\n\nFinally, we can run our regressions. Following the authors, we test the effect of being awarded a new road and receiving the road on the log forest cover as well as on the average forest cover.\n\n\n\nOur results align with the authors’ findings presented in Table 3 which show that being awarded a road has a negative impact on forest cover (approximately 0.5% loss in the construction period between being awarded a road and its completion), but after the road is constructed, forest cover appears to return. This could incorrectly be interpreted as a positive effect of roads on tree cover if the award term is left out. This determination that rural roads have no effect on forest loss, in combination with the authors’ additional findings of substantial forest loss due to highway construction, have important policy implications for governments considering similar infrastructure expansion. The use of VCF data in this study enabled significant insights, and the potential use cases for VCF data remain numerous.\n\n\n\n",
    "preview": {},
    "last_modified": "2023-10-25T09:38:16+08:00",
    "input_file": {}
  }
]
